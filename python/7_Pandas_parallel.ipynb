{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel split-apply-combine\n",
    "\n",
    "A nice property of split-apply-combine is that it is well suited to parallel computation, in the sense that the apply part can be done independently in parallel. The disadvantage is that you cannot use the quick-and-easy functionality we used above, as you need to do each part separately.\n",
    "\n",
    "We now proceed with exercises where you\n",
    "\n",
    "1. Use the python multiprocessing module to do the apply part in parallel.\n",
    "2. Use slurm array jobs to do the apply part in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split-apply-combine using multiprocessing\n",
    "\n",
    "Here we use the Pool class in the multiprocessing module, which is an easy way to parallelize simple tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  1  processes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-10.52098626754912, pvalue=8.985235037486755e-18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import os\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import scipy.stats as stats\n",
    "\n",
    "d = pd.read_csv(os.path.join(pd.__path__[0], 'tests/data/iris.csv'), dtype={'Name': 'category'})\n",
    "\n",
    "sz = os.getenv('OMP_NUM_THREADS', 1)\n",
    "sz2 = os.getenv('SLURM_CPUS_PER_TASK', 1)\n",
    "sz = max(sz, sz2)\n",
    "print(\"Using \", sz, \" processes.\")\n",
    "def f(x):\n",
    "    return x[1].describe()\n",
    "pool = Pool(sz)\n",
    "\n",
    "res = pool.map(f, d.groupby('Name'))\n",
    "# Calculate e.g. t-test for difference in sepallength between setosa and versicolor\n",
    "rs = res[0]['SepalLength']\n",
    "rv = res[1]['SepalLength']\n",
    "stats.ttest_ind_from_stats(rs['mean'], rs['std'], rs['count'], rv['mean'], rv['std'], rv['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel split-apply-combine with slurm array jobs\n",
    "\n",
    "For this we need to step outside the warm confines of the jupyter notebook and face the cold, hard reality of the shell. You will need several python scripts, and several slurm batch scripts. What you need is\n",
    "\n",
    "- A python script to read the original dataset and split it into separate datasets, and then write each dataset into a separate file. This is the *split* phase.\n",
    "- A python script to read in a dataset (a split dataset generated in the previous step), and perform the operation we're interested in, and write the part to an output file. This is the *apply* phase, and can be run in parallel, once for each dataset.\n",
    "- A python script that combines the results of the apply phase and generates the final result. This is the *combine* phase.\n",
    "- A slurm batch script to run the split phase, and then submits jobs for the apply and combine phases. *Hint*: For the apply phases, you should use a slurm array job.\n",
    "- A slurm batch script to run the combine phase. *Hint*: This job needs to use slurm job dependencies so that it only runs after the successful completion of the apply phase jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solutions to this can be found in the repo in the directory `python/split-apply-combine-parallel`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
