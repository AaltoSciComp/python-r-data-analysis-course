{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O\n",
    "\n",
    "Typically when doing data analysis you want to read and write data from various file formats. In this exercise session we'll go through some common file formats\n",
    "- Basic Python I/O\n",
    "- Numpy txt I/O\n",
    "- Pandas CSV I/O\n",
    "- Pandas SQL I/O\n",
    "\n",
    "## Basic Python I/O\n",
    "\n",
    "The basic python I/O is useful if you have some file in some custom format and you need to do some manual processing of it as part of creating whatever in-memory datastructure you need. To start with, lets create a file to play around with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open('pangrams.txt', 'w') as f:\n",
    "    f.write(\"\"\"The quick brown fox jumps over the lazy dog\n",
    "Sphinx of black quartz, judge my vow\n",
    "The dog ate my homework\n",
    "Pack my box with five dozen liquor jugs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering, why the \"with\" thing instead of just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = open('pangrams.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python, a \"with\"-block ensures that resources declared are released when exiting the block. In this case it means that when we exit the block the file will be closed. So we don't have to close it explicitly (also: exception-safety!).\n",
    "\n",
    "Classes which implement the so-called \"context-manager\" protocol can be used in with-statements.\n",
    "\n",
    "A pangram is a sentence which contains all the characters in the alphabet. In the file we just created we have one pangram per row. Or are they actually pangrams?\n",
    "\n",
    "**Exercise**: Read the file pangrams.txt we just created, and write a snippet to check whether each pangram is, in fact, a pangram (i.e. does it use every letter in the English alphabet?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web (HTTP) I/O\n",
    "\n",
    "It's fairly straightforward to read from a website as well. e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234041\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "with urllib.request.urlopen('https://www.gutenberg.org/files/219/219-0.txt') as f:\n",
    "    data = f.read()\n",
    "print((len(data))) # Or whatever you want to do with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Use the various string methods and/or regular expressions to retrieve the author and title of the document we just downloaded from the Gutenberg project. **Hint**: That information can be found as lines with \"Author: XXXX\" and \"Title: YYYY\" in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy I/O\n",
    "\n",
    "Numpy provides some basic routines which can be useful if you need to load data to/from a Numpy ndarray. For reading/writing textfiles there is ``loadtxt`` and ``savetxt``. See also ``genfromtxt`` with more sophisticated handling of missing values etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a=np.loadtxt(StringIO(\"1 2 3\\n4 5 6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test.npy', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.load('test.npy')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.zeros((200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('test-with-zeros.npz', b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('test-with-zeros-compressed.npz', b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary IO of Numpy ndarrays defines a so-called ``.npy`` format. Reading/writing these files can be done with the ``load`` and ``save`` methods. There's also the ``.npz`` format, which is a zip archive containing several numpy ndarrays in one file. ``.npz`` format files can be read/written with ``load``, ``savez`` and ``savez_compressed`` methods. This is a good choice for temporary or intermediate files such as checkpoints etc. Note that the format is Numpy-specific, and other languages might not easily be able to read it. Similarly, for long-term archiving other formats might be a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas I/O\n",
    "\n",
    "For dataframes, \"natural\" file formats are things that support tabular data, like CSV files and RDBMS (\"SQL databases\"). Pandas provides the ``read_csv`` function for reading CSV files (see also other pandas ``read_*`` functions). Similarly, for writinig data there is ``to_csv`` as well as other ``to_*`` functions.\n",
    "\n",
    "For binary I/O, Pandas supports a bunch of them. As was mentioned in the R sessions, the ``feather`` format is a fast binary format supported by both Pandas and R, so if you need intermediate files and/or interoperability with R, that is a good choice.\n",
    "\n",
    "Pandas also provides some convenience functions for doing SQL queries and reading the data directly into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"test.sq3\")\n",
    "c = conn.cursor()\n",
    "c.execute('''create table if not exists test (date integer primary key, alloc integer not null, total integer not null)''')\n",
    "conn.commit()\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "d = pd.read_csv('../data/iris.csv', dtype={'Name': 'category'})\n",
    "d.to_sql('iris', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  sepal_length  sepal_width  petal_length  petal_width species\n",
       "0      0           5.1          3.5           1.4          0.2  setosa\n",
       "1      1           4.9          3.0           1.4          0.2  setosa\n",
       "2      2           4.7          3.2           1.3          0.2  setosa\n",
       "3      3           4.6          3.1           1.5          0.2  setosa\n",
       "4      4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = pd.read_sql_query('select * from iris', conn)\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: The file data/nvutil.sq3 contains an SQLite database with utilization data for the Triton GPU nodes over a time interval. Read that data into a Pandas dataframe, and plot the utilization as a function of time. **Hint** Open a shell, use the ``sqlite3`` command to open the database, then you can use the ``.tables`` command to list the tables in the DB, and ``.schema TABLENAME`` to view the schema of a table. Also note that sq SQLite does not have any native datetime datatype, data in the date column is stored as seconds since the epoch (1970-01-01T00:00)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
